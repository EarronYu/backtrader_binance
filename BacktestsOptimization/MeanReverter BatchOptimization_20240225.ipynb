{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanReverter Strategy Batch Optimization\n",
    "\n",
    "这个notebook用于对多个交易对进行MeanReverter策略的批量优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x7498\\anaconda3\\envs\\backtrader\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库...\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import backtrader as bt  # 替换 backtesting 为 backtrader\n",
    "import optuna\n",
    "import warnings\n",
    "import quantstats as qs\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 在此处添加全局缓存字典，用于缓存数据加载结果和数据完整性检查结果\n",
    "_data_feed_cache = {}\n",
    "_data_completeness_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MeanReverter' from 'MeanReverter' (c:\\Users\\x7498\\Documents\\GitHub\\backtrader_binance_futures\\BacktestsOptimization\\MeanReverter.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMeanReverter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MeanReverter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 在 CONFIG 中添加所有需要动态配置的参数\u001b[39;00m\n\u001b[0;32m      4\u001b[0m CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 策略相关配置\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     },\n\u001b[0;32m     60\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'MeanReverter' from 'MeanReverter' (c:\\Users\\x7498\\Documents\\GitHub\\backtrader_binance_futures\\BacktestsOptimization\\MeanReverter.py)"
     ]
    }
   ],
   "source": [
    "from MeanReverter import MeanReverter\n",
    "\n",
    "# 在 CONFIG 中添加所有需要动态配置的参数\n",
    "CONFIG = {\n",
    "    # 策略相关配置\n",
    "    'strategy': {\n",
    "        'class': MeanReverter,\n",
    "        'name': MeanReverter.__name__\n",
    "    },\n",
    "    \n",
    "    # 数据相关配置（单币种、单时间周期）\n",
    "    # 如果 selected_symbols 为空，则通过 get_all_symbols 自动获取所有交易对\n",
    "    'selected_symbols': [],\n",
    "    'data_path': r'\\\\znas\\\\Main\\\\futures',\n",
    "    'start_date': '2024-01-01',\n",
    "    'end_date': '2025-02-08',\n",
    "    'source_timeframe': '1m',\n",
    "    # 针对批量优化使用多个目标时间周期\n",
    "    'target_timeframes': ['15min', '30min', '1H'],\n",
    "    \n",
    "    # 文件保存配置\n",
    "    'reports_path': 'reports',\n",
    "    'results_filename_template': 'optimization_results_{strategy_name}_{start_date}-{end_date}.csv',\n",
    "    \n",
    "    # 回测参数配置\n",
    "    'commission': 0.0004,\n",
    "    'initial_capital': 10000,\n",
    "    # 如果需要可以添加：\n",
    "    # 'trade_on_close': True,\n",
    "    # 'exclusive_orders': True,\n",
    "    # 'hedging': False,\n",
    "    \n",
    "    # 优化参数配置，根据 MeanReverter 策略的参数进行优化\n",
    "    'optimization_params': {\n",
    "        'frequency': range(15, 31),            # 用于计算慢速 RSI 均线的周期，默认值为22\n",
    "        'rsiFrequency': range(30, 46),          # 计算 RSI 的周期，默认值为36\n",
    "        'buyZoneDistance': range(1, 8),         # RSI 相对于慢速 RSI 均线的折扣比例，默认值为3\n",
    "        'avgDownATRSum': range(3, 8),           # 用于计算 ATR 累积值的周期数，默认值为5\n",
    "        'useAbsoluteRSIBarrier': [True, False], # 是否使用绝对 RSI 阈值进行平仓，默认值为True\n",
    "        'barrierLevel': range(55, 66),          # RSI 阻力水平，默认值为60\n",
    "        'pyramiding': range(2, 5)               # 最大允许加仓次数，默认值为3\n",
    "    },\n",
    "    \n",
    "    # 优化设置\n",
    "    'optimization_settings': {\n",
    "        'n_trials': 188,       # 可根据需要调整试验次数\n",
    "        'min_trades': 50,\n",
    "        'timeout': 3600,\n",
    "        'n_jobs': 30           # -1 表示使用所有 CPU 核心; 也可以设置为具体的数量\n",
    "    },\n",
    "    \n",
    "    # 评分权重配置（如果用于计算最终得分）\n",
    "    'score_weights': {\n",
    "        'ret_weight': 0.6,\n",
    "        'sqn_weight': 0.4,\n",
    "        'sharpe_weight': 0.2,\n",
    "        'win_rate_weight': 0.15,\n",
    "        'dd_weight': 0.1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeframe_params(timeframe_str):\n",
    "    \"\"\"\n",
    "    将时间周期字符串转换为 backtrader 的 timeframe 和 compression 参数\n",
    "    \"\"\"\n",
    "    if timeframe_str.endswith('min'):\n",
    "        return (bt.TimeFrame.Minutes, int(timeframe_str.replace('min', '')))\n",
    "    elif timeframe_str.endswith('H'):\n",
    "        return (bt.TimeFrame.Minutes, int(timeframe_str.replace('H', '')) * 60)\n",
    "    elif timeframe_str.endswith('D'):\n",
    "        return (bt.TimeFrame.Days, 1)\n",
    "    elif timeframe_str == '1m':\n",
    "        return (bt.TimeFrame.Minutes, 1)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的时间周期格式: {timeframe_str}\")\n",
    "\n",
    "def load_and_resample_data(symbol, start_date, end_date, source_timeframe='1m', target_timeframe='30min', data_path=r'\\\\znas\\\\Main\\\\futures'):\n",
    "    \"\"\"\n",
    "    加载并重采样期货数据，并缓存已经重采样后的 DataFrame 以避免重复 I/O 操作\n",
    "    \"\"\"\n",
    "    # 构造缓存键\n",
    "    key = (symbol, start_date, end_date, source_timeframe, target_timeframe, data_path)\n",
    "    if key in _data_feed_cache:\n",
    "        # 如果缓存中有，返回新的数据馈送对象（注意拷贝，防止被修改）\n",
    "        cached_df = _data_feed_cache[key]\n",
    "        timeframe, compression = get_timeframe_params(target_timeframe)\n",
    "        return bt.feeds.PandasData(\n",
    "            dataname=cached_df.copy(),\n",
    "            open='Open',\n",
    "            high='High',\n",
    "            low='Low',\n",
    "            close='Close',\n",
    "            volume='Volume',\n",
    "            openinterest=-1,\n",
    "            timeframe=timeframe,\n",
    "            compression=compression,\n",
    "            fromdate=pd.to_datetime(start_date),\n",
    "            todate=pd.to_datetime(end_date)\n",
    "        )\n",
    "    \n",
    "    # 生成日期范围\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    all_data = []\n",
    "    \n",
    "    # 标准化交易对名称\n",
    "    formatted_symbol = symbol.replace('/', '_').replace(':', '_')\n",
    "    if not formatted_symbol.endswith('USDT'):\n",
    "        formatted_symbol = f\"{formatted_symbol}USDT\"\n",
    "    \n",
    "    # 遍历每一天\n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        # 构建文件路径\n",
    "        file_path = os.path.join(data_path, date_str, f\"{date_str}_{formatted_symbol}_USDT_{source_timeframe}.csv\")\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                # 读取数据\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "                all_data.append(df)\n",
    "            else:\n",
    "                print(f\"文件不存在: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件出错 {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(f\"未找到 {symbol} 在指定日期范围内的数据\")\n",
    "    \n",
    "    # 合并、排序，以及重采样数据\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('datetime')\n",
    "    combined_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    resampled = combined_df.resample(target_timeframe).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    }).dropna()  # 立即删除NaN值\n",
    "    \n",
    "    backtesting_df = pd.DataFrame({\n",
    "        'Open': resampled['open'],\n",
    "        'High': resampled['high'],\n",
    "        'Low': resampled['low'],\n",
    "        'Close': resampled['close'],\n",
    "        'Volume': resampled['volume']\n",
    "    })\n",
    "    \n",
    "    # 确保所有数据都是数值类型并删除任何无效值\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        backtesting_df[col] = pd.to_numeric(backtesting_df[col], errors='coerce')\n",
    "    backtesting_df = backtesting_df.dropna()\n",
    "    \n",
    "    # 将结果缓存在全局变量中（使用拷贝，以免后续被修改）\n",
    "    _data_feed_cache[key] = backtesting_df.copy()\n",
    "    \n",
    "    timeframe, compression = get_timeframe_params(target_timeframe)\n",
    "    data_feed = bt.feeds.PandasData(\n",
    "        dataname=backtesting_df,\n",
    "        open='Open',\n",
    "        high='High',\n",
    "        low='Low',\n",
    "        close='Close',\n",
    "        volume='Volume',\n",
    "        openinterest=-1,\n",
    "        timeframe=timeframe,\n",
    "        compression=compression,\n",
    "        fromdate=pd.to_datetime(start_date),\n",
    "        todate=pd.to_datetime(end_date)\n",
    "    )\n",
    "    return data_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_symbols(data_path, date_str):\n",
    "    \"\"\"获取指定日期目录下的所有交易对\"\"\"\n",
    "    daily_path = os.path.join(data_path, date_str)\n",
    "    if not os.path.exists(daily_path):\n",
    "        return []\n",
    "    \n",
    "    files = glob(os.path.join(daily_path, f\"{date_str}_*_USDT_1m.csv\"))\n",
    "    symbols = set()  # 使用 set 进行去重\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "        symbol = filename.split('_')[1]\n",
    "        symbols.add(symbol)\n",
    "    return list(symbols)\n",
    "\n",
    "def verify_data_completeness(symbol, start_date, end_date, data_path):\n",
    "    \"\"\"验证数据完整性\"\"\"\n",
    "    # 构造缓存键\n",
    "    key = (symbol, start_date, end_date, data_path)\n",
    "    if key in _data_completeness_cache:\n",
    "        return _data_completeness_cache[key]\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # 标准化交易对名称\n",
    "    formatted_symbol = symbol.replace('/', '_').replace(':', '_')\n",
    "    if not formatted_symbol.endswith('USDT'):\n",
    "        formatted_symbol = f\"{formatted_symbol}USDT\"\n",
    "    \n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        file_path = os.path.join(\n",
    "            data_path,\n",
    "            date_str,\n",
    "            f\"{date_str}_{formatted_symbol}_USDT_1m.csv\"  # 文件名格式保持不变\n",
    "        )\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"文件不存在: {file_path}\")\n",
    "            _data_completeness_cache[key] = False\n",
    "            return False\n",
    "    _data_completeness_cache[key] = True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加自定义评分函数\n",
    "def custom_score(strat, weights=CONFIG['score_weights']):\n",
    "    \"\"\"自定义评分函数\"\"\"\n",
    "    # 获取各项指标\n",
    "    sharpe = strat.analyzers.sharpe.get_analysis().get('sharperatio', 0)\n",
    "    drawdown = strat.analyzers.drawdown.get_analysis()\n",
    "    max_dd = drawdown['max']['drawdown'] if 'max' in drawdown else 0\n",
    "    returns = strat.analyzers.returns.get_analysis()\n",
    "    total_return = returns.get('rtot', 0) * 100\n",
    "    trades = strat.analyzers.trades.get_analysis()\n",
    "    total_trades = trades.get('total', {}).get('total', 0)\n",
    "    won_trades = trades.get('won', {}).get('total', 0)\n",
    "    win_rate = (won_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "    sqn = strat.analyzers.sqn.get_analysis().get('sqn', 0)\n",
    "    \n",
    "    # 计算惩罚项\n",
    "    dd_penalty = 1 / (1 + abs(max_dd / 100))\n",
    "    trade_penalty = 1 if total_trades >= CONFIG['optimization_settings']['min_trades'] else total_trades / CONFIG['optimization_settings']['min_trades']\n",
    "    \n",
    "    # 计算总分\n",
    "    score = (\n",
    "        weights['ret_weight'] * (total_return / 100) +\n",
    "        weights['sqn_weight'] * sqn +\n",
    "        weights['sharpe_weight'] * sharpe +\n",
    "        weights['win_rate_weight'] * (win_rate / 100) +\n",
    "        weights['dd_weight'] * dd_penalty\n",
    "    ) * trade_penalty\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_strategy(symbol, timeframe):\n",
    "    \"\"\"\n",
    "    使用 Optuna 优化策略参数，并返回最优的前 5 个参数组合\n",
    "    \"\"\"\n",
    "    # 构造数据库文件路径，增加了 SQLite 连接参数 timeout 和 check_same_thread\n",
    "    storage_path = f\"sqlite:///{CONFIG['reports_path']}/optuna_{CONFIG['strategy']['name']}_{symbol}_{timeframe}.db?timeout=30000&check_same_thread=False\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"{symbol}_{timeframe}\",\n",
    "        direction=\"maximize\",\n",
    "        storage=storage_path,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    \n",
    "    def objective(trial):\n",
    "        try:\n",
    "            params = {}\n",
    "            for param_name, param_range in CONFIG['optimization_params'].items():\n",
    "                if isinstance(param_range, range):\n",
    "                    params[param_name] = trial.suggest_int(\n",
    "                        param_name,\n",
    "                        param_range.start,\n",
    "                        param_range.stop - 1,\n",
    "                        param_range.step\n",
    "                    )\n",
    "                else:\n",
    "                    params[param_name] = trial.suggest_categorical(param_name, param_range)\n",
    "            \n",
    "            cerebro = bt.Cerebro()\n",
    "            data = load_and_resample_data(\n",
    "                symbol, CONFIG['start_date'], CONFIG['end_date'],\n",
    "                target_timeframe=timeframe\n",
    "            )\n",
    "            cerebro.adddata(data)\n",
    "            cerebro.addstrategy(CONFIG['strategy']['class'], **params)\n",
    "            \n",
    "            cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')\n",
    "            cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')\n",
    "            cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')\n",
    "            cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')\n",
    "            cerebro.addanalyzer(bt.analyzers.SQN, _name='sqn')\n",
    "            \n",
    "            results = cerebro.run()\n",
    "            strat = results[0]\n",
    "            score = custom_score(strat)\n",
    "            return score\n",
    "        except Exception as e:\n",
    "            print(f\"Trial encountered an error: {e}\")\n",
    "            # 返回极低的分数，确保该试验不会被选中\n",
    "            return float('-inf')\n",
    "    \n",
    "    # 在 study.optimize 里并行执行多个 Trial（n_jobs 参数从 CONFIG 中读取）\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=CONFIG['optimization_settings']['n_trials'],\n",
    "        timeout=CONFIG['optimization_settings']['timeout'],\n",
    "        n_jobs=CONFIG['optimization_settings'].get('n_jobs', 1)\n",
    "    )\n",
    "    \n",
    "    # 提取前 5 个最佳试验（保持原有逻辑）\n",
    "    completed_trials = [\n",
    "        t for t in study.trials\n",
    "        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None\n",
    "    ]\n",
    "    top_trials = sorted(completed_trials, key=lambda t: t.value, reverse=True)[:5]\n",
    "    \n",
    "    top_results = []\n",
    "    for t in top_trials:\n",
    "        result = t.params.copy()\n",
    "        result['score'] = t.value\n",
    "        top_results.append(result)\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backtest_with_params(params, symbol, timeframe):\n",
    "    \"\"\"\n",
    "    使用指定参数运行策略的回测并计算收益指标（利用 quantstats）。\n",
    "    返回一个包含基础回测指标和所有 quantstats 指标的字典。\n",
    "    \"\"\"\n",
    "    # 过滤掉不属于策略参数部分的键（如 'score', 'symbol', 'timeframe'等）\n",
    "    valid_keys = set(CONFIG[\"optimization_params\"].keys())\n",
    "    strategy_params = {k: v for k, v in params.items() if k in valid_keys}\n",
    "\n",
    "    cerebro = bt.Cerebro()\n",
    "    data = load_and_resample_data(symbol, CONFIG['start_date'], CONFIG['end_date'],\n",
    "                                  target_timeframe=timeframe)\n",
    "    cerebro.adddata(data)\n",
    "    # 只传入过滤后的策略参数\n",
    "    cerebro.addstrategy(CONFIG['strategy']['class'], **strategy_params)\n",
    "\n",
    "    initial_capital = CONFIG['initial_capital']\n",
    "    cerebro.broker.setcash(initial_capital)\n",
    "    cerebro.broker.setcommission(commission=CONFIG['commission'])\n",
    "\n",
    "    # 添加常用分析器，包括 PyFolio 用于后续量化指标计算\n",
    "    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')\n",
    "    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "\n",
    "    results = cerebro.run()\n",
    "    strat = results[0]\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    profit = final_value - initial_capital\n",
    "    roi = (profit / initial_capital) * 100\n",
    "\n",
    "    # 获取 PyFolio 的回测收益率数据\n",
    "    portfolio_stats = strat.analyzers.pyfolio.get_pf_items()\n",
    "    returns = portfolio_stats[0]\n",
    "    returns.index = returns.index.tz_convert(None)\n",
    "\n",
    "    # 计算量化指标（完整的收益指标）\n",
    "    qs_stats = {}\n",
    "    try:\n",
    "        qs_stats[\"Sharpe Ratio\"] = qs.stats.sharpe(returns)\n",
    "        qs_stats[\"Sortino Ratio\"] = qs.stats.sortino(returns)\n",
    "        qs_stats[\"Calmar Ratio\"] = qs.stats.calmar(returns)\n",
    "        qs_stats[\"Max Drawdown\"] = qs.stats.max_drawdown(returns)\n",
    "        qs_stats[\"Win Rate\"] = qs.stats.win_rate(returns)\n",
    "        qs_stats[\"Profit Factor\"] = qs.stats.profit_factor(returns)\n",
    "        qs_stats[\"Expected Return (M)\"] = qs.stats.expected_return(returns, aggregate='M')\n",
    "        qs_stats[\"Kelly Criterion\"] = qs.stats.kelly_criterion(returns)\n",
    "        qs_stats[\"Risk of Ruin\"] = qs.stats.risk_of_ruin(returns)\n",
    "        qs_stats[\"Tail Ratio\"] = qs.stats.tail_ratio(returns)\n",
    "        qs_stats[\"Common Sense Ratio\"] = qs.stats.common_sense_ratio(returns)\n",
    "        qs_stats[\"Average Win\"] = qs.stats.avg_win(returns)\n",
    "        qs_stats[\"Average Loss\"] = qs.stats.avg_loss(returns)\n",
    "        qs_stats[\"Annualized Volatility\"] = qs.stats.volatility(returns, periods=252)\n",
    "        qs_stats[\"Skew\"] = qs.stats.skew(returns)\n",
    "        qs_stats[\"Kurtosis\"] = qs.stats.kurtosis(returns)\n",
    "        qs_stats[\"Value at Risk\"] = qs.stats.value_at_risk(returns)\n",
    "        qs_stats[\"Conditional VaR\"] = qs.stats.conditional_value_at_risk(returns)\n",
    "        qs_stats[\"Payoff Ratio\"] = qs.stats.payoff_ratio(returns)\n",
    "        qs_stats[\"Gain to Pain Ratio\"] = qs.stats.gain_to_pain_ratio(returns)\n",
    "        qs_stats[\"Ulcer Index\"] = qs.stats.ulcer_index(returns)\n",
    "        qs_stats[\"Consecutive Wins\"] = qs.stats.consecutive_wins(returns)\n",
    "        qs_stats[\"Consecutive Losses\"] = qs.stats.consecutive_losses(returns)\n",
    "        # ----------------- 新增指标 -----------------\n",
    "        qs_stats[\"Avg Return\"] = qs.stats.avg_return(returns)\n",
    "        qs_stats[\"CAGR\"] = qs.stats.cagr(returns)\n",
    "        qs_stats[\"Expected Shortfall\"] = qs.stats.expected_shortfall(returns)\n",
    "        qs_stats[\"Information Ratio\"] = qs.stats.information_ratio(returns)\n",
    "        qs_stats[\"Profit Ratio\"] = qs.stats.profit_ratio(returns)\n",
    "        qs_stats[\"R2\"] = qs.stats.r2(returns)\n",
    "        qs_stats[\"R Squared\"] = qs.stats.r_squared(returns)\n",
    "        qs_stats[\"Recovery Factor\"] = qs.stats.recovery_factor(returns)\n",
    "        qs_stats[\"Risk-Return Ratio\"] = qs.stats.risk_return_ratio(returns)\n",
    "        qs_stats[\"Win/Loss Ratio\"] = qs.stats.win_loss_ratio(returns)\n",
    "        qs_stats[\"Worst\"] = qs.stats.worst(returns)\n",
    "        # ------------------------------------------------\n",
    "    except Exception as e:\n",
    "        qs_stats[\"error\"] = str(e)\n",
    "\n",
    "    # 整合基础回测指标与量化收益指标\n",
    "    backtest_results = {\n",
    "        \"Initial Capital\": initial_capital,\n",
    "        \"Final Value\": final_value,\n",
    "        \"Profit\": profit,\n",
    "        \"ROI (%)\": roi,\n",
    "    }\n",
    "    backtest_results.update(qs_stats)\n",
    "\n",
    "    return backtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_results(config):\n",
    "    \"\"\"\n",
    "    加载全局优化结果文件，并提取已完成优化的组合（基于 'Symbol', 'Target Timeframe', 'Rank' 列）。\n",
    "    \"\"\"\n",
    "    # 构造 master 文件路径\n",
    "    start_clean = config['start_date'].replace(\"-\", \"\")\n",
    "    end_clean = config['end_date'].replace(\"-\", \"\")\n",
    "    master_file = os.path.join(\n",
    "        config['reports_path'], \n",
    "        config['results_filename_template'].format(\n",
    "            strategy_name=config['strategy']['name'],\n",
    "            start_date=start_clean,\n",
    "            end_date=end_clean\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(master_file):\n",
    "        try:\n",
    "            master_df = pd.read_excel(master_file)\n",
    "        except Exception as e:\n",
    "            master_df = pd.read_csv(master_file)\n",
    "    else:\n",
    "        master_df = pd.DataFrame()\n",
    "    \n",
    "    optimized_combinations = set()\n",
    "    if not master_df.empty:\n",
    "        if {'Target Timeframe', 'Symbol', 'Rank'}.issubset(master_df.columns):\n",
    "            for symbol in master_df['Symbol'].unique():\n",
    "                for tf in master_df['Target Timeframe'].unique():\n",
    "                    rows = master_df[(master_df['Symbol'] == symbol) & (master_df['Target Timeframe'] == tf)]\n",
    "                    ranks = rows['Rank'].tolist()\n",
    "                    # 当存在 5 个排名且排名为 1 到 5 时认为该组合已完成优化\n",
    "                    if len(ranks) == 5 and set(ranks) == set(range(1, 6)):\n",
    "                        optimized_combinations.add((symbol, tf))\n",
    "        else:\n",
    "            print(\"警告: 结果文件缺少必要的列，将重新开始优化\")\n",
    "    else:\n",
    "        print(\"优化结果文件为空\")\n",
    "        \n",
    "    return master_file, master_df, optimized_combinations\n",
    "\n",
    "def save_master_results(new_results, master_file):\n",
    "    \"\"\"\n",
    "    将新的优化结果合并到全局结果文件中，并保存为 CSV 文件。\n",
    "    \"\"\"\n",
    "    if os.path.exists(master_file):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(master_file)\n",
    "        except Exception as e:\n",
    "            existing_df = pd.DataFrame()\n",
    "        combined_df = pd.concat([existing_df, pd.DataFrame(new_results)], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = pd.DataFrame(new_results)\n",
    "    \n",
    "    combined_df.to_csv(master_file, index=False)  # 修改为 CSV 写入\n",
    "    print(f\"优化结果保存到: {master_file}\")\n",
    "\n",
    "def process_symbol_tf(symbol, tf, config):\n",
    "    \"\"\"\n",
    "    针对单个交易对和指定时间周期执行策略参数优化与回测，并赋予 1~5 的排名。\n",
    "    \"\"\"\n",
    "    print(f\"\\n开始针对 {symbol} 时间周期 {tf} 优化...\")\n",
    "    # 使用已有的 optimize_strategy 函数\n",
    "    top_results = optimize_strategy(symbol, tf)\n",
    "    if not top_results:\n",
    "        print(f\"警告: {symbol} 在 {tf} 时间周期下优化失败\")\n",
    "        return []\n",
    "    \n",
    "    processed_results = []\n",
    "    # 为每个参数组合运行回测并获取量化指标，同时赋予排名\n",
    "    for idx, res in enumerate(top_results, start=1):\n",
    "        res['Symbol'] = symbol\n",
    "        res['Target Timeframe'] = tf\n",
    "        res['Rank'] = idx\n",
    "        metrics = run_backtest_with_params(res, symbol, tf)\n",
    "        res.update(metrics)\n",
    "        processed_results.append(res)\n",
    "        \n",
    "    print(f\"完成 {symbol} 在 {tf} 时间周期下的优化，获得 {len(processed_results)} 个结果\")\n",
    "    return processed_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增清理函数：清理不在最终结果 CSV 中的 optuna 数据库文件\n",
    "def clean_incomplete_optuna_db_files(config):\n",
    "    \"\"\"\n",
    "    清理不在最终优化结果 CSV 中的 optuna 数据库文件。\n",
    "    该函数会读取最终结果 CSV（如果存在），提取已完成优化的 (Symbol, Target Timeframe) 组合，\n",
    "    然后删除 reports 目录下不在该列表中的 optuna 数据库文件。\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from glob import glob\n",
    "\n",
    "    # 从最终结果 CSV 中加载已完成优化组合\n",
    "    master_file, master_df, optimized_combinations = load_master_results(config)\n",
    "    print(f\"已完成优化组合: {optimized_combinations}\")\n",
    "    \n",
    "    # 匹配与当前策略相关的 optuna 数据库文件\n",
    "    pattern = os.path.join(config['reports_path'], f\"optuna_{config['strategy']['name']}_*.db\")\n",
    "    db_files = glob(pattern)\n",
    "    for db_file in db_files:\n",
    "        filename = os.path.basename(db_file)\n",
    "        prefix = f\"optuna_{config['strategy']['name']}_\"\n",
    "        # 确保文件名格式正确\n",
    "        if filename.startswith(prefix) and filename.endswith(\".db\"):\n",
    "            # 去掉前缀和后缀，得到 \"symbol_timeframe\"\n",
    "            core = filename[len(prefix):-3]  # 去掉后面的 \".db\"\n",
    "            parts = core.rsplit(\"_\", 1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            symbol, timeframe = parts\n",
    "            # 如果此组合不在最终结果中，则删除该数据库文件\n",
    "            if (symbol, timeframe) not in optimized_combinations:\n",
    "                try:\n",
    "                    os.remove(db_file)\n",
    "                    print(f\"已删除未完成优化的数据库文件：{db_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"删除文件 {db_file} 出错：{e}\")\n",
    "    print(\"数据库清理完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_optimize(config):\n",
    "    \"\"\"\n",
    "    批量优化所有交易对和指定多个时间周期：\n",
    "    1. 根据配置中的 selected_symbols 获取交易对列表（如果为空则自动获取）。\n",
    "    2. 验证每个交易对在指定时间段内数据完整性，跳过数据不完整的。\n",
    "    3. 对每个（交易对, 时间周期）组合，若已存在完整5个排名则跳过，否则运行优化与回测。\n",
    "    4. 每完成一个交易对-时间周期组合的前五个优化结果，立刻保存到全局结果文件中。\n",
    "    \"\"\"\n",
    "    os.makedirs(config['reports_path'], exist_ok=True)\n",
    "    \n",
    "    master_file, master_df, optimized_combinations = load_master_results(config)\n",
    "    \n",
    "    # 获取交易对列表\n",
    "    if config.get('selected_symbols'):\n",
    "        symbols = config['selected_symbols']\n",
    "    else:\n",
    "        symbols = get_all_symbols(config['data_path'], config['start_date'])\n",
    "        print(f\"总共找到 {len(symbols)} 个交易对\")\n",
    "    \n",
    "    total_combinations = [(s, tf) for s in symbols for tf in config['target_timeframes']]\n",
    "    remaining_combinations = [combo for combo in total_combinations if combo not in optimized_combinations]\n",
    "    print(f\"剩余需要优化的组合数量: {len(remaining_combinations)} 个\")\n",
    "    \n",
    "    # 遍历每个交易对\n",
    "    for i, symbol in enumerate(symbols, 1):\n",
    "        print(f\"\\n正在处理第 {i}/{len(symbols)} 个交易对: {symbol}\")\n",
    "        print(f\"验证 {symbol} 的数据完整性...\")\n",
    "        if not verify_data_completeness(symbol, config['start_date'], config['end_date'], config['data_path']):\n",
    "            print(f\"警告: 跳过 {symbol} - 数据不完整\")\n",
    "            continue\n",
    "        print(f\"{symbol} 数据完整性验证通过\")\n",
    "        \n",
    "        # 对每个目标时间周期进行优化\n",
    "        for tf in config['target_timeframes']:\n",
    "            if (symbol, tf) in optimized_combinations:\n",
    "                print(f\"组合 {symbol}-{tf} 已完成优化，跳过\")\n",
    "                continue\n",
    "            results = process_symbol_tf(symbol, tf, config)\n",
    "            if results:\n",
    "                clear_output(wait=True)  # 清除当前 cell 的所有输出\n",
    "                save_master_results(results, master_file)\n",
    "                # 更新已优化组合，避免重复处理\n",
    "                optimized_combinations.add((symbol, tf))\n",
    "            else:\n",
    "                print(f\"警告: {symbol} 在 {tf} 时间周期下没有获得优化结果\")\n",
    "    print(\"批量优化完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 04:17:36,954] A new study created in RDB with name: ROSEUSDT_30min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化结果保存到: reports\\optimization_results_MeanReverter_20240101-20250208.csv\n",
      "\n",
      "开始针对 ROSEUSDT 时间周期 30min 优化...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-01 04:19:30,314] Trial 15 finished with value: 0.7771029754635087 and parameters: {'frequency': 17, 'rsiFrequency': 42, 'buyZoneDistance': 7, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 60, 'pyramiding': 4}. Best is trial 15 with value: 0.7771029754635087.\n",
      "[I 2025-03-01 04:19:54,103] Trial 2 finished with value: 0.48628117904521706 and parameters: {'frequency': 23, 'rsiFrequency': 37, 'buyZoneDistance': 5, 'avgDownATRSum': 4, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 63, 'pyramiding': 3}. Best is trial 5 with value: 0.9664107797486305.\n",
      "[I 2025-03-01 04:20:09,842] Trial 5 finished with value: 0.9664107797486305 and parameters: {'frequency': 23, 'rsiFrequency': 38, 'buyZoneDistance': 7, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 65, 'pyramiding': 4}. Best is trial 5 with value: 0.9664107797486305.\n",
      "[I 2025-03-01 04:20:11,675] Trial 0 finished with value: 0.8155175778030233 and parameters: {'frequency': 29, 'rsiFrequency': 33, 'buyZoneDistance': 6, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 60, 'pyramiding': 3}. Best is trial 5 with value: 0.9664107797486305.\n",
      "[I 2025-03-01 04:20:13,100] Trial 14 finished with value: 0.043687121753425165 and parameters: {'frequency': 25, 'rsiFrequency': 35, 'buyZoneDistance': 5, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 63, 'pyramiding': 2}. Best is trial 5 with value: 0.9664107797486305.\n",
      "[I 2025-03-01 04:21:06,585] Trial 6 finished with value: 0.5771200077610972 and parameters: {'frequency': 15, 'rsiFrequency': 42, 'buyZoneDistance': 3, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 61, 'pyramiding': 4}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:07,573] Trial 13 finished with value: 0.4009990257300554 and parameters: {'frequency': 22, 'rsiFrequency': 31, 'buyZoneDistance': 3, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 61, 'pyramiding': 3}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:08,293] Trial 4 finished with value: 0.9682776243134218 and parameters: {'frequency': 17, 'rsiFrequency': 38, 'buyZoneDistance': 7, 'avgDownATRSum': 7, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 57, 'pyramiding': 3}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:08,419] Trial 28 finished with value: 0.18326328720697502 and parameters: {'frequency': 24, 'rsiFrequency': 36, 'buyZoneDistance': 5, 'avgDownATRSum': 6, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 61, 'pyramiding': 3}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:11,917] Trial 3 finished with value: -0.38304655658355724 and parameters: {'frequency': 15, 'rsiFrequency': 40, 'buyZoneDistance': 2, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 55, 'pyramiding': 4}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:14,000] Trial 22 finished with value: -0.4828840312734054 and parameters: {'frequency': 24, 'rsiFrequency': 32, 'buyZoneDistance': 7, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 63, 'pyramiding': 3}. Best is trial 4 with value: 0.9682776243134218.\n",
      "[I 2025-03-01 04:21:16,503] Trial 21 finished with value: -1.0222202900831756 and parameters: {'frequency': 17, 'rsiFrequency': 43, 'buyZoneDistance': 5, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 62, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:16,594] Trial 9 finished with value: 0.3153083153555211 and parameters: {'frequency': 22, 'rsiFrequency': 42, 'buyZoneDistance': 3, 'avgDownATRSum': 6, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 60, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:17,984] Trial 17 finished with value: -1.054845230005491 and parameters: {'frequency': 25, 'rsiFrequency': 37, 'buyZoneDistance': 1, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 59, 'pyramiding': 3}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:18,266] Trial 1 finished with value: 0.6066294604179615 and parameters: {'frequency': 28, 'rsiFrequency': 38, 'buyZoneDistance': 1, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 56, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:19,292] Trial 12 finished with value: 0.932207897119398 and parameters: {'frequency': 24, 'rsiFrequency': 41, 'buyZoneDistance': 5, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 61, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:19,350] Trial 16 finished with value: 0.6508611697496257 and parameters: {'frequency': 30, 'rsiFrequency': 45, 'buyZoneDistance': 7, 'avgDownATRSum': 4, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 55, 'pyramiding': 2}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:22,850] Trial 18 finished with value: 0.9833519065586979 and parameters: {'frequency': 21, 'rsiFrequency': 40, 'buyZoneDistance': 6, 'avgDownATRSum': 4, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 65, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:43,405] Trial 10 finished with value: -0.38204941437394646 and parameters: {'frequency': 29, 'rsiFrequency': 30, 'buyZoneDistance': 7, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 56, 'pyramiding': 2}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:44,855] Trial 11 finished with value: -0.1093732579012596 and parameters: {'frequency': 28, 'rsiFrequency': 40, 'buyZoneDistance': 7, 'avgDownATRSum': 6, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 57, 'pyramiding': 3}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:21:45,046] Trial 8 finished with value: -0.0713639790667585 and parameters: {'frequency': 30, 'rsiFrequency': 32, 'buyZoneDistance': 1, 'avgDownATRSum': 3, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 59, 'pyramiding': 3}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:14,792] Trial 19 finished with value: -2.8069240799309116 and parameters: {'frequency': 16, 'rsiFrequency': 43, 'buyZoneDistance': 1, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 62, 'pyramiding': 3}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:24,633] Trial 30 finished with value: 0.1858375375957723 and parameters: {'frequency': 19, 'rsiFrequency': 30, 'buyZoneDistance': 1, 'avgDownATRSum': 7, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 56, 'pyramiding': 2}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:30,455] Trial 29 finished with value: 0.8135214994749915 and parameters: {'frequency': 19, 'rsiFrequency': 31, 'buyZoneDistance': 4, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 55, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:30,499] Trial 24 finished with value: -0.39147739981676277 and parameters: {'frequency': 25, 'rsiFrequency': 38, 'buyZoneDistance': 2, 'avgDownATRSum': 5, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 63, 'pyramiding': 3}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:39,497] Trial 20 finished with value: -0.4583033402143724 and parameters: {'frequency': 18, 'rsiFrequency': 42, 'buyZoneDistance': 6, 'avgDownATRSum': 4, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 57, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:46,573] Trial 26 finished with value: 0.6910009863444417 and parameters: {'frequency': 15, 'rsiFrequency': 36, 'buyZoneDistance': 6, 'avgDownATRSum': 7, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 61, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:52,463] Trial 32 finished with value: 0.9445945312318684 and parameters: {'frequency': 20, 'rsiFrequency': 39, 'buyZoneDistance': 6, 'avgDownATRSum': 7, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 65, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:22:52,662] Trial 7 finished with value: -0.061850395469808986 and parameters: {'frequency': 19, 'rsiFrequency': 34, 'buyZoneDistance': 4, 'avgDownATRSum': 6, 'useAbsoluteRSIBarrier': True, 'barrierLevel': 63, 'pyramiding': 4}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:23:00,358] Trial 31 finished with value: 0.9127042305840956 and parameters: {'frequency': 20, 'rsiFrequency': 34, 'buyZoneDistance': 6, 'avgDownATRSum': 7, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 65, 'pyramiding': 2}. Best is trial 18 with value: 0.9833519065586979.\n",
      "[I 2025-03-01 04:23:07,262] Trial 23 finished with value: 0.8460420687086414 and parameters: {'frequency': 21, 'rsiFrequency': 43, 'buyZoneDistance': 7, 'avgDownATRSum': 6, 'useAbsoluteRSIBarrier': False, 'barrierLevel': 63, 'pyramiding': 2}. Best is trial 18 with value: 0.9833519065586979.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 先清理不完整的 Optuna 数据库文件（不在最终结果 CSV 中的组合）\n",
    "    clean_incomplete_optuna_db_files(CONFIG)\n",
    "    batch_optimize(CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backtrader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
