{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanReverter Strategy Batch Optimization\n",
    "\n",
    "这个notebook用于对多个交易对进行MeanReverter策略的批量优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\x7498\\anaconda3\\envs\\backtrader\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库...\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import backtrader as bt \n",
    "import optuna\n",
    "import warnings\n",
    "import quantstats as qs\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path  # 使用pathlib代替os\n",
    "# 添加必要的导入\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# _data_loading_executor = ThreadPoolExecutor(max_workers=10)  # 用于数据加载的线程池\n",
    "\n",
    "# 遍历每个交易对，但使用多进程方式\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "# 在此处添加全局缓存字典，用于缓存数据加载结果和数据完整性检查结果\n",
    "_data_feed_cache = {}\n",
    "_data_completeness_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeanReverter import MeanReverter\n",
    "\n",
    "# 在 CONFIG 中添加所有需要动态配置的参数\n",
    "CONFIG = {\n",
    "    # 策略相关配置\n",
    "    'strategy': {\n",
    "        'class': MeanReverter,\n",
    "        'name': MeanReverter.__name__\n",
    "    },\n",
    "    \n",
    "    # 数据相关配置（单币种、单时间周期）\n",
    "    # 如果 selected_symbols 为空，则通过 get_all_symbols 自动获取所有交易对\n",
    "    'selected_symbols': [],\n",
    "    'data_path': r'\\\\znas\\\\Main\\\\futures',\n",
    "    'start_date': '2024-01-01',\n",
    "    'end_date': '2025-02-08',\n",
    "    'source_timeframe': '1m',\n",
    "    # 针对批量优化使用多个目标时间周期\n",
    "    'target_timeframes': ['1H'],\n",
    "    \n",
    "    # 文件保存配置\n",
    "    'reports_path': 'reports',\n",
    "    'results_filename_template': 'optimization_results_{strategy_name}_{start_date}-{end_date}.csv',\n",
    "    \n",
    "    # 回测参数配置\n",
    "    'commission': 0.0004,\n",
    "    'initial_capital': 10000,\n",
    "    # 如果需要可以添加：\n",
    "    # 'trade_on_close': True,\n",
    "    # 'exclusive_orders': True,\n",
    "    # 'hedging': False,\n",
    "    \n",
    "    # 优化参数配置，根据 MeanReverter 策略的参数进行优化\n",
    "    'optimization_params': {\n",
    "        'frequency': range(15, 31, 2),            # 用于计算慢速 RSI 均线的周期，步长为2\n",
    "        'rsiFrequency': range(30, 46, 2),         # 计算 RSI 的周期，步长为2\n",
    "        'buyZoneDistance': range(1, 8, 1),        # RSI 相对于慢速 RSI 均线的折扣比例，步长为1\n",
    "        'avgDownATRSum': range(3, 8, 1),          # 用于计算 ATR 累积值的周期数，步长为1\n",
    "        'useAbsoluteRSIBarrier': [True, False],   # 是否使用绝对 RSI 阈值进行平仓\n",
    "        'barrierLevel': range(55, 66, 2),         # RSI 阻力水平，步长为2\n",
    "        'pyramiding': range(2, 5, 1)              # 最大允许加仓次数，步长为1\n",
    "    },\n",
    "    \n",
    "    # 优化设置\n",
    "    'optimization_settings': {\n",
    "        'n_trials': 20,       # 可根据需要调整试验次数\n",
    "        'min_trades': 50,\n",
    "        'timeout': 3600,\n",
    "        'n_jobs': 40           # -1 表示使用所有 CPU 核心; 也可以设置为具体的数量\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeframe_params(timeframe_str):\n",
    "    \"\"\"\n",
    "    将时间周期字符串转换为 backtrader 的 timeframe 和 compression 参数\n",
    "    \"\"\"\n",
    "    if timeframe_str.endswith('min'):\n",
    "        return (bt.TimeFrame.Minutes, int(timeframe_str.replace('min', '')))\n",
    "    elif timeframe_str.endswith('H'):\n",
    "        return (bt.TimeFrame.Minutes, int(timeframe_str.replace('H', '')) * 60)\n",
    "    elif timeframe_str.endswith('D'):\n",
    "        return (bt.TimeFrame.Days, 1)\n",
    "    elif timeframe_str == '1m':\n",
    "        return (bt.TimeFrame.Minutes, 1)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的时间周期格式: {timeframe_str}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_and_resample_data(symbol, start_date, end_date, source_timeframe='1m', target_timeframe='30min', data_path=r'\\\\znas\\\\Main\\\\futures'):\n",
    "    \"\"\"\n",
    "    加载并重采样期货数据，并缓存已经重采样后的 DataFrame 以避免重复 I/O 操作\n",
    "    \"\"\"\n",
    "    # 构造缓存键\n",
    "    key = (symbol, start_date, end_date, source_timeframe, target_timeframe, data_path)\n",
    "    if key in _data_feed_cache:\n",
    "        # 如果缓存中有，返回新的数据馈送对象（注意拷贝，防止被修改）\n",
    "        cached_df = _data_feed_cache[key]\n",
    "        timeframe, compression = get_timeframe_params(target_timeframe)\n",
    "        data_feed = bt.feeds.PandasData(\n",
    "            dataname=cached_df.copy(),\n",
    "            open='Open',\n",
    "            high='High',\n",
    "            low='Low',\n",
    "            close='Close',\n",
    "            volume='Volume',\n",
    "            openinterest=-1,\n",
    "            timeframe=timeframe,\n",
    "            compression=compression,\n",
    "            fromdate=pd.to_datetime(start_date),\n",
    "            todate=pd.to_datetime(end_date)\n",
    "        )\n",
    "        \n",
    "        # 添加clone方法，这样可以快速创建数据副本而不需要重新执行IO\n",
    "        data_feed.clone = lambda: bt.feeds.PandasData(\n",
    "            dataname=cached_df.copy(),\n",
    "            open='Open',\n",
    "            high='High',\n",
    "            low='Low',\n",
    "            close='Close',\n",
    "            volume='Volume',\n",
    "            openinterest=-1,\n",
    "            timeframe=timeframe,\n",
    "            compression=compression,\n",
    "            fromdate=pd.to_datetime(start_date),\n",
    "            todate=pd.to_datetime(end_date)\n",
    "        )\n",
    "        \n",
    "        return data_feed\n",
    "    \n",
    "    # 生成日期范围\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    all_data = []\n",
    "    \n",
    "    # 标准化交易对名称\n",
    "    formatted_symbol = symbol.replace('/', '_').replace(':', '_')\n",
    "    if not formatted_symbol.endswith('USDT'):\n",
    "        formatted_symbol = f\"{formatted_symbol}USDT\"\n",
    "    \n",
    "    # 顺序读取文件，不使用线程池\n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        # 构建文件路径\n",
    "        file_path = os.path.join(data_path, date_str, f\"{date_str}_{formatted_symbol}_USDT_{source_timeframe}.csv\")\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                # 读取数据\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "                all_data.append(df)\n",
    "            else:\n",
    "                print(f\"文件不存在: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件出错 {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_data:\n",
    "        raise ValueError(f\"未找到 {symbol} 在指定日期范围内的数据\")\n",
    "    \n",
    "    # 合并、排序，以及重采样数据\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('datetime')\n",
    "    combined_df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    resampled = combined_df.resample(target_timeframe).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    }).dropna()  # 立即删除NaN值\n",
    "    \n",
    "    backtesting_df = pd.DataFrame({\n",
    "        'Open': resampled['open'],\n",
    "        'High': resampled['high'],\n",
    "        'Low': resampled['low'],\n",
    "        'Close': resampled['close'],\n",
    "        'Volume': resampled['volume']\n",
    "    })\n",
    "    \n",
    "    # 确保所有数据都是数值类型并删除任何无效值\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        backtesting_df[col] = pd.to_numeric(backtesting_df[col], errors='coerce')\n",
    "    backtesting_df = backtesting_df.dropna()\n",
    "    \n",
    "    # 将结果缓存在全局变量中（使用拷贝，以免后续被修改）\n",
    "    _data_feed_cache[key] = backtesting_df.copy()\n",
    "    \n",
    "    timeframe, compression = get_timeframe_params(target_timeframe)\n",
    "    data_feed = bt.feeds.PandasData(\n",
    "        dataname=backtesting_df,\n",
    "        open='Open',\n",
    "        high='High',\n",
    "        low='Low',\n",
    "        close='Close',\n",
    "        volume='Volume',\n",
    "        openinterest=-1,\n",
    "        timeframe=timeframe,\n",
    "        compression=compression,\n",
    "        fromdate=pd.to_datetime(start_date),\n",
    "        todate=pd.to_datetime(end_date)\n",
    "    )\n",
    "    \n",
    "    # 添加clone方法\n",
    "    data_feed.clone = lambda: bt.feeds.PandasData(\n",
    "        dataname=backtesting_df.copy(),\n",
    "        open='Open',\n",
    "        high='High',\n",
    "        low='Low',\n",
    "        close='Close',\n",
    "        volume='Volume',\n",
    "        openinterest=-1,\n",
    "        timeframe=timeframe,\n",
    "        compression=compression,\n",
    "        fromdate=pd.to_datetime(start_date),\n",
    "        todate=pd.to_datetime(end_date)\n",
    "    )\n",
    "    \n",
    "    return data_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeanReverter import MeanReverter\n",
    "\n",
    "# 在 CONFIG 中添加所有需要动态配置的参数\n",
    "CONFIG = {\n",
    "    # 策略相关配置\n",
    "    'strategy': {\n",
    "        'class': MeanReverter,\n",
    "        'name': MeanReverter.__name__\n",
    "    },\n",
    "    \n",
    "    # 数据相关配置（单币种、单时间周期）\n",
    "    # 如果 selected_symbols 为空，则通过 get_all_symbols 自动获取所有交易对\n",
    "    'selected_symbols': [],\n",
    "    'data_path': r'..\\data\\binance_futures_data.db',\n",
    "    'start_date': '2024-01-01',\n",
    "    'end_date': '2025-02-08',\n",
    "    'source_timeframe': '1m',\n",
    "    # 针对批量优化使用多个目标时间周期\n",
    "    'target_timeframes': ['15min', '30min', '1H'],\n",
    "    \n",
    "    # 文件保存配置\n",
    "    'reports_path': 'reports',\n",
    "    'results_filename_template': 'optimization_results_{strategy_name}_{start_date}-{end_date}.csv',\n",
    "    \n",
    "    # 回测参数配置\n",
    "    'commission': 0.0004,\n",
    "    'initial_capital': 10000,\n",
    "    # 如果需要可以添加：\n",
    "    # 'trade_on_close': True,\n",
    "    # 'exclusive_orders': True,\n",
    "    # 'hedging': False,\n",
    "    \n",
    "    # 优化参数配置，根据 MeanReverter 策略的参数进行优化\n",
    "    'optimization_params': {\n",
    "        'frequency': range(15, 31),            # 用于计算慢速 RSI 均线的周期，默认值为22\n",
    "        'rsiFrequency': range(30, 46),          # 计算 RSI 的周期，默认值为36\n",
    "        'buyZoneDistance': range(1, 8),         # RSI 相对于慢速 RSI 均线的折扣比例，默认值为3\n",
    "        'avgDownATRSum': range(3, 8),           # 用于计算 ATR 累积值的周期数，默认值为5\n",
    "        'useAbsoluteRSIBarrier': [True, False], # 是否使用绝对 RSI 阈值进行平仓，默认值为True\n",
    "        'barrierLevel': range(55, 66),          # RSI 阻力水平，默认值为60\n",
    "        'pyramiding': range(2, 5)               # 最大允许加仓次数，默认值为3\n",
    "    },\n",
    "    \n",
    "    # 优化设置\n",
    "    'optimization_settings': {\n",
    "        'n_trials': 188,       # 可根据需要调整试验次数\n",
    "        'min_trades': 50,\n",
    "        'timeout': 3600,\n",
    "        'n_jobs': 30           # -1 表示使用所有 CPU 核心; 也可以设置为具体的数量\n",
    "    },\n",
    "    \n",
    "    # 评分权重配置（如果用于计算最终得分）\n",
    "    'score_weights': {\n",
    "        'ret_weight': 0.6,\n",
    "        'sqn_weight': 0.4,\n",
    "        'sharpe_weight': 0.2,\n",
    "        'win_rate_weight': 0.15,\n",
    "        'dd_weight': 0.1,\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_symbols(data_path, date_str):\n",
    "    \"\"\"获取指定日期目录下的所有交易对\"\"\"\n",
    "    daily_path = os.path.join(data_path, date_str)\n",
    "    if not os.path.exists(daily_path):\n",
    "        print(f\"数据目录不存在: {daily_path}\")\n",
    "        # 尝试查找附近的日期\n",
    "        parent_dir = os.path.dirname(daily_path)\n",
    "        if os.path.exists(parent_dir):\n",
    "            available_dates = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]\n",
    "            if available_dates:\n",
    "                print(f\"可用的日期目录: {available_dates[:5]}{'...' if len(available_dates) > 5 else ''}\")\n",
    "        return []\n",
    "    \n",
    "    # 搜索所有以 \"_USDT_1m.csv\" 结尾的文件\n",
    "    pattern = os.path.join(daily_path, f\"*_USDT_1m.csv\")\n",
    "    files = glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"在目录 {daily_path} 中没有找到符合模式的文件\")\n",
    "        # 列出目录中的部分文件以进行调试\n",
    "        try:\n",
    "            all_files = os.listdir(daily_path)[:10]  # 只显示前10个文件\n",
    "            print(f\"目录中的部分文件: {all_files}\")\n",
    "        except Exception as e:\n",
    "            print(f\"无法列出目录内容: {str(e)}\")\n",
    "    \n",
    "    symbols = set()  # 使用 set 进行去重\n",
    "    for file in files:\n",
    "        try:\n",
    "            filename = os.path.basename(file)\n",
    "            # 提取格式为 \"YYYY-MM-DD_SYMBOL_USDT_1m.csv\" 中的 SYMBOL 部分\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                symbol = parts[1]\n",
    "                symbols.add(symbol)\n",
    "        except Exception as e:\n",
    "            print(f\"处理文件名 {file} 出错: {str(e)}\")\n",
    "    \n",
    "    if not symbols:\n",
    "        print(\"警告: 未能提取到任何交易对\")\n",
    "    else:\n",
    "        print(f\"成功提取了 {len(symbols)} 个交易对\")\n",
    "    \n",
    "    return list(symbols)\n",
    "\n",
    "def verify_data_completeness(symbol, start_date, end_date, data_path):\n",
    "    \"\"\"验证数据完整性\"\"\"\n",
    "    # 构造缓存键\n",
    "    key = (symbol, start_date, end_date, data_path)\n",
    "    if key in _data_completeness_cache:\n",
    "        return _data_completeness_cache[key]\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # 标准化交易对名称\n",
    "    formatted_symbol = symbol.replace('/', '_').replace(':', '_')\n",
    "    if not formatted_symbol.endswith('USDT'):\n",
    "        formatted_symbol = f\"{formatted_symbol}USDT\"\n",
    "    \n",
    "    for date in date_range:\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        file_path = os.path.join(\n",
    "            data_path,\n",
    "            date_str,\n",
    "            f\"{date_str}_{formatted_symbol}_USDT_1m.csv\"  # 文件名格式保持不变\n",
    "        )\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"文件不存在: {file_path}\")\n",
    "            _data_completeness_cache[key] = False\n",
    "            return False\n",
    "    _data_completeness_cache[key] = True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加自定义评分函数\n",
    "def custom_score(strat):\n",
    "    \"\"\"\n",
    "    自定义评分函数 - 以最大化回报率为主要目标\n",
    "    保留最低交易次数要求作为基本约束\n",
    "    \"\"\"\n",
    "    # 获取交易次数\n",
    "    trades = strat.analyzers.trades.get_analysis()\n",
    "    total_trades = trades.get('total', {}).get('total', 0)\n",
    "    \n",
    "    # 从returns分析器获取总回报率\n",
    "    returns = strat.analyzers.returns.get_analysis()\n",
    "    total_return = returns.get('rtot', 0) * 100  # 转为百分比\n",
    "    \n",
    "    # 交易次数惩罚 - 确保策略至少有足够的交易\n",
    "    min_trades = CONFIG['optimization_settings'].get('min_trades', 50)\n",
    "    trade_penalty = 1.0 if total_trades >= min_trades else (total_trades / min_trades) ** 2\n",
    "    \n",
    "    # 最终得分简单地使用调整后的回报率\n",
    "    # 交易次数不足的策略会受到严厉惩罚\n",
    "    score = total_return * trade_penalty\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_strategy(symbol, timeframe):\n",
    "    \"\"\"\n",
    "    使用 Optuna 优化策略参数，并返回最优的前 5 个参数组合\n",
    "    \"\"\"\n",
    "    # 1. 预加载数据，只执行一次IO操作\n",
    "    preloaded_data = load_and_resample_data(\n",
    "        symbol, CONFIG['start_date'], CONFIG['end_date'],\n",
    "        target_timeframe=timeframe\n",
    "    )\n",
    "    \n",
    "    # 使用内存存储而非SQLite数据库\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"{symbol}_{timeframe}\",\n",
    "        direction=\"maximize\",\n",
    "        storage=None  # 使用内存存储\n",
    "    )\n",
    "    \n",
    "    print(f\"开始优化 {symbol}-{timeframe}...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        try:\n",
    "            params = {}\n",
    "            for param_name, param_range in CONFIG['optimization_params'].items():\n",
    "                if isinstance(param_range, range):\n",
    "                    params[param_name] = trial.suggest_int(\n",
    "                        param_name,\n",
    "                        param_range.start,\n",
    "                        param_range.stop - 1,\n",
    "                        param_range.step\n",
    "                    )\n",
    "                else:\n",
    "                    params[param_name] = trial.suggest_categorical(param_name, param_range)\n",
    "            \n",
    "            cerebro = bt.Cerebro(\n",
    "                        optdatas=True,    # 启用数据优化\n",
    "                        optreturn=True,   # 仅返回必要结果\n",
    "                        runonce=True,     # 批处理模式\n",
    "                        preload=True      # 预加载数据\n",
    "            )\n",
    "            # 2. 使用预加载数据的克隆而不是重新加载数据\n",
    "            data = preloaded_data.clone()\n",
    "            cerebro.adddata(data)\n",
    "            cerebro.addstrategy(CONFIG['strategy']['class'], **params)\n",
    "            \n",
    "            # cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')\n",
    "            # cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')\n",
    "            cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')\n",
    "            cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')\n",
    "            # cerebro.addanalyzer(bt.analyzers.SQN, _name='sqn')\n",
    "            \n",
    "            results = cerebro.run()\n",
    "            strat = results[0]\n",
    "            score = custom_score(strat)\n",
    "            \n",
    "            # 每个Trial都会输出一行信息\n",
    "            print(f\"[{symbol}-{timeframe}] Trial {trial.number}: 参数 {params} -> 得分 {score:.2f}\")\n",
    "            \n",
    "            return score\n",
    "        except Exception as e:\n",
    "            print(f\"[{symbol}-{timeframe}] Trial {trial.number} 出错: {e}\")\n",
    "            # 返回极低的分数，确保该试验不会被选中\n",
    "            return float('-inf')\n",
    "    \n",
    "    # 在 study.optimize 里并行执行多个 Trial\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=CONFIG['optimization_settings']['n_trials'],\n",
    "        timeout=CONFIG['optimization_settings']['timeout'],\n",
    "        n_jobs=CONFIG['optimization_settings'].get('n_jobs', 1),\n",
    "        catch=(Exception,)  # 捕获所有异常\n",
    "    )\n",
    "    \n",
    "    print(f\"完成 {symbol}-{timeframe} 的优化\")\n",
    "    \n",
    "    # 提取前 5 个最佳试验\n",
    "    completed_trials = [\n",
    "        t for t in study.trials\n",
    "        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None and t.value > float('-inf')\n",
    "    ]\n",
    "    \n",
    "    if not completed_trials:\n",
    "        print(f\"警告: {symbol}-{timeframe} 没有有效的完成试验\")\n",
    "        return []\n",
    "    \n",
    "    top_trials = sorted(completed_trials, key=lambda t: t.value, reverse=True)[:5]\n",
    "    \n",
    "    print(f\"[{symbol}-{timeframe}] 最佳参数组合:\")\n",
    "    top_results = []\n",
    "    for i, t in enumerate(top_trials, 1):\n",
    "        result = t.params.copy()\n",
    "        result['score'] = t.value\n",
    "        top_results.append(result)\n",
    "        print(f\"  Rank {i}: 得分 {t.value:.2f}, 参数: {t.params}\")\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backtest_with_params(params, symbol, timeframe):\n",
    "    \"\"\"\n",
    "    使用指定参数运行策略的回测并计算收益指标（利用 quantstats）。\n",
    "    返回一个包含基础回测指标和所有 quantstats 指标的字典。\n",
    "    \"\"\"\n",
    "    # 过滤掉不属于策略参数部分的键（如 'score', 'symbol', 'timeframe'等）\n",
    "    valid_keys = set(CONFIG[\"optimization_params\"].keys())\n",
    "    strategy_params = {k: v for k, v in params.items() if k in valid_keys}\n",
    "\n",
    "    cerebro = bt.Cerebro(\n",
    "                optdatas=True,    # 启用数据优化\n",
    "                optreturn=True,   # 仅返回必要结果\n",
    "                runonce=True,     # 批处理模式\n",
    "                preload=True      # 预加载数据\n",
    "    )\n",
    "    data = load_and_resample_data(symbol, CONFIG['start_date'], CONFIG['end_date'],\n",
    "                                  target_timeframe=timeframe)\n",
    "    cerebro.adddata(data)\n",
    "    # 只传入过滤后的策略参数\n",
    "    cerebro.addstrategy(CONFIG['strategy']['class'], **strategy_params)\n",
    "\n",
    "    initial_capital = CONFIG['initial_capital']\n",
    "    cerebro.broker.setcash(initial_capital)\n",
    "    cerebro.broker.setcommission(commission=CONFIG['commission'])\n",
    "\n",
    "    # 添加常用分析器，包括 PyFolio 用于后续量化指标计算\n",
    "    # cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe')\n",
    "    # cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')\n",
    "    cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "\n",
    "    results = cerebro.run()\n",
    "    strat = results[0]\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    profit = final_value - initial_capital\n",
    "    roi = (profit / initial_capital) * 100\n",
    "\n",
    "    # 获取 PyFolio 的回测收益率数据\n",
    "    portfolio_stats = strat.analyzers.pyfolio.get_pf_items()\n",
    "    returns = portfolio_stats[0]\n",
    "    \n",
    "    # 修改这里：确保索引没有时区信息，避免使用tz_convert\n",
    "    # 首先检查是否有时区信息再进行处理\n",
    "    try:\n",
    "        if hasattr(returns.index, 'tz') and returns.index.tz is not None:\n",
    "            returns.index = returns.index.tz_localize(None)\n",
    "    except:\n",
    "        # 如果无法处理时区，创建一个新的无时区索引\n",
    "        try:\n",
    "            returns = pd.Series(returns.values, index=pd.DatetimeIndex(returns.index.astype('datetime64[ns]')))\n",
    "        except:\n",
    "            # 如果依然失败，使用更简单的方法\n",
    "            returns = pd.Series(returns.values, index=pd.DatetimeIndex([str(idx) for idx in returns.index]))\n",
    "\n",
    "    # 计算量化指标（完整的收益指标）\n",
    "    qs_stats = {}\n",
    "    try:\n",
    "        qs_stats[\"Sharpe Ratio\"] = qs.stats.sharpe(returns)\n",
    "        qs_stats[\"Sortino Ratio\"] = qs.stats.sortino(returns)\n",
    "        qs_stats[\"Calmar Ratio\"] = qs.stats.calmar(returns)\n",
    "        qs_stats[\"Max Drawdown\"] = qs.stats.max_drawdown(returns)\n",
    "        qs_stats[\"Win Rate\"] = qs.stats.win_rate(returns)\n",
    "        qs_stats[\"Profit Factor\"] = qs.stats.profit_factor(returns)\n",
    "        qs_stats[\"Expected Return (M)\"] = qs.stats.expected_return(returns, aggregate='M')\n",
    "        qs_stats[\"Kelly Criterion\"] = qs.stats.kelly_criterion(returns)\n",
    "        qs_stats[\"Risk of Ruin\"] = qs.stats.risk_of_ruin(returns)\n",
    "        qs_stats[\"Tail Ratio\"] = qs.stats.tail_ratio(returns)\n",
    "        qs_stats[\"Common Sense Ratio\"] = qs.stats.common_sense_ratio(returns)\n",
    "        qs_stats[\"Average Win\"] = qs.stats.avg_win(returns)\n",
    "        qs_stats[\"Average Loss\"] = qs.stats.avg_loss(returns)\n",
    "        qs_stats[\"Annualized Volatility\"] = qs.stats.volatility(returns, periods=252)\n",
    "        qs_stats[\"Skew\"] = qs.stats.skew(returns)\n",
    "        qs_stats[\"Kurtosis\"] = qs.stats.kurtosis(returns)\n",
    "        qs_stats[\"Value at Risk\"] = qs.stats.value_at_risk(returns)\n",
    "        qs_stats[\"Conditional VaR\"] = qs.stats.conditional_value_at_risk(returns)\n",
    "        qs_stats[\"Payoff Ratio\"] = qs.stats.payoff_ratio(returns)\n",
    "        qs_stats[\"Gain to Pain Ratio\"] = qs.stats.gain_to_pain_ratio(returns)\n",
    "        qs_stats[\"Ulcer Index\"] = qs.stats.ulcer_index(returns)\n",
    "        qs_stats[\"Consecutive Wins\"] = qs.stats.consecutive_wins(returns)\n",
    "        qs_stats[\"Consecutive Losses\"] = qs.stats.consecutive_losses(returns)\n",
    "        # ----------------- 新增指标 -----------------\n",
    "        qs_stats[\"Avg Return\"] = qs.stats.avg_return(returns)\n",
    "        qs_stats[\"CAGR\"] = qs.stats.cagr(returns)\n",
    "        qs_stats[\"Expected Shortfall\"] = qs.stats.expected_shortfall(returns)\n",
    "        qs_stats[\"Information Ratio\"] = qs.stats.information_ratio(returns)\n",
    "        qs_stats[\"Profit Ratio\"] = qs.stats.profit_ratio(returns)\n",
    "        qs_stats[\"R2\"] = qs.stats.r2(returns)\n",
    "        qs_stats[\"R Squared\"] = qs.stats.r_squared(returns)\n",
    "        qs_stats[\"Recovery Factor\"] = qs.stats.recovery_factor(returns)\n",
    "        qs_stats[\"Risk-Return Ratio\"] = qs.stats.risk_return_ratio(returns)\n",
    "        qs_stats[\"Win/Loss Ratio\"] = qs.stats.win_loss_ratio(returns)\n",
    "        qs_stats[\"Worst\"] = qs.stats.worst(returns)\n",
    "        # ------------------------------------------------\n",
    "    except Exception as e:\n",
    "        qs_stats[\"error\"] = str(e)\n",
    "\n",
    "    # 整合基础回测指标与量化收益指标\n",
    "    backtest_results = {\n",
    "        \"Initial Capital\": initial_capital,\n",
    "        \"Final Value\": final_value,\n",
    "        \"Profit\": profit,\n",
    "        \"ROI (%)\": roi,\n",
    "    }\n",
    "    backtest_results.update(qs_stats)\n",
    "\n",
    "    return backtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_results(config):\n",
    "    \"\"\"\n",
    "    加载全局优化结果文件，并提取已完成优化的组合（基于 'Symbol', 'Target Timeframe', 'Rank' 列）。\n",
    "    \"\"\"\n",
    "    # 构造 master 文件路径\n",
    "    start_clean = config['start_date'].replace(\"-\", \"\")\n",
    "    end_clean = config['end_date'].replace(\"-\", \"\")\n",
    "    master_file = os.path.join(\n",
    "        config['reports_path'], \n",
    "        config['results_filename_template'].format(\n",
    "            strategy_name=config['strategy']['name'],\n",
    "            start_date=start_clean,\n",
    "            end_date=end_clean\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(master_file):\n",
    "        try:\n",
    "            master_df = pd.read_excel(master_file)\n",
    "        except Exception as e:\n",
    "            master_df = pd.read_csv(master_file)\n",
    "    else:\n",
    "        master_df = pd.DataFrame()\n",
    "    \n",
    "    optimized_combinations = set()\n",
    "    if not master_df.empty:\n",
    "        if {'Target Timeframe', 'Symbol', 'Rank'}.issubset(master_df.columns):\n",
    "            for symbol in master_df['Symbol'].unique():\n",
    "                for tf in master_df['Target Timeframe'].unique():\n",
    "                    rows = master_df[(master_df['Symbol'] == symbol) & (master_df['Target Timeframe'] == tf)]\n",
    "                    ranks = rows['Rank'].tolist()\n",
    "                    # 当存在 5 个排名且排名为 1 到 5 时认为该组合已完成优化\n",
    "                    if len(ranks) == 5 and set(ranks) == set(range(1, 6)):\n",
    "                        optimized_combinations.add((symbol, tf))\n",
    "        else:\n",
    "            print(\"警告: 结果文件缺少必要的列，将重新开始优化\")\n",
    "    else:\n",
    "        print(\"优化结果文件为空\")\n",
    "        \n",
    "    return master_file, master_df, optimized_combinations\n",
    "\n",
    "def save_master_results(new_results, master_file):\n",
    "    \"\"\"\n",
    "    将新的优化结果合并到全局结果文件中，并保存为 CSV 文件。\n",
    "    \"\"\"\n",
    "    if os.path.exists(master_file):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(master_file)\n",
    "        except Exception as e:\n",
    "            existing_df = pd.DataFrame()\n",
    "        combined_df = pd.concat([existing_df, pd.DataFrame(new_results)], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = pd.DataFrame(new_results)\n",
    "    \n",
    "    combined_df.to_csv(master_file, index=False)  # 修改为 CSV 写入\n",
    "    print(f\"优化结果保存到: {master_file}\")\n",
    "\n",
    "def process_symbol_tf(symbol, tf, config):\n",
    "    \"\"\"\n",
    "    针对单个交易对和指定时间周期执行策略参数优化与回测，并赋予 1~5 的排名。\n",
    "    \"\"\"\n",
    "    print(f\"\\n开始针对 {symbol} 时间周期 {tf} 优化...\")\n",
    "    # 使用已有的 optimize_strategy 函数\n",
    "    top_results = optimize_strategy(symbol, tf)\n",
    "    if not top_results:\n",
    "        print(f\"警告: {symbol} 在 {tf} 时间周期下优化失败\")\n",
    "        return []\n",
    "    \n",
    "    processed_results = []\n",
    "    # 为每个参数组合运行回测并获取量化指标，同时赋予排名\n",
    "    for idx, res in enumerate(top_results, start=1):\n",
    "        res['Symbol'] = symbol\n",
    "        res['Target Timeframe'] = tf\n",
    "        res['Rank'] = idx\n",
    "        metrics = run_backtest_with_params(res, symbol, tf)  # 这行可能出错\n",
    "        res.update(metrics)\n",
    "        processed_results.append(res)\n",
    "        \n",
    "    print(f\"完成 {symbol} 在 {tf} 时间周期下的优化，获得 {len(processed_results)} 个结果\")\n",
    "    return processed_results\n",
    "\n",
    "def process_symbol_batch(symbol, timeframes, config_path):\n",
    "    \"\"\"用于并行处理的包装函数,避免传递大型配置对象\"\"\"\n",
    "    try:\n",
    "        # 在子进程中重新加载配置,避免序列化问题\n",
    "        import json\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "            \n",
    "        # 导入必要的模块(每个进程需要单独导入)\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import optuna\n",
    "        import backtrader as bt\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        print(f\"开始处理交易对: {symbol}\")\n",
    "        # 验证数据完整性\n",
    "        if not verify_data_completeness(symbol, config['start_date'], config['end_date'], config['data_path']):\n",
    "            print(f\"警告: 跳过 {symbol} - 数据不完整\")\n",
    "            return []\n",
    "        \n",
    "        # 处理每个时间周期\n",
    "        for tf in timeframes:\n",
    "            print(f\"处理组合: {symbol}-{tf}\")\n",
    "            # 使用内存存储优化\n",
    "            top_results = optimize_strategy(symbol, tf)\n",
    "            if not top_results:\n",
    "                continue\n",
    "                \n",
    "            processed_results = []\n",
    "            # 为每个参数组合运行回测并获取量化指标\n",
    "            # 为每个参数组合运行回测并获取量化指标，同时赋予排名\n",
    "            for idx, res in enumerate(top_results, start=1):\n",
    "                res['Symbol'] = symbol\n",
    "                res['Target Timeframe'] = tf\n",
    "                res['Rank'] = idx\n",
    "                metrics = run_backtest_with_params(res, symbol, tf)\n",
    "                res.update(metrics)\n",
    "                processed_results.append(res)\n",
    "            \n",
    "            results.extend(processed_results)\n",
    "            print(f\"完成组合 {symbol}-{tf} 的优化\")\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = f\"处理 {symbol} 时出错: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return [{\"error\": error_msg, \"Symbol\": symbol}]\n",
    "\n",
    "def batch_optimize(config):\n",
    "    \"\"\"\n",
    "    批量优化所有交易对和指定多个时间周期，使用多线程保持输出实时性\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(config['reports_path'], exist_ok=True)\n",
    "    \n",
    "    master_file, master_df, optimized_combinations = load_master_results(config)\n",
    "    \n",
    "    # 获取交易对列表\n",
    "    if config.get('selected_symbols'):\n",
    "        symbols = config['selected_symbols']\n",
    "    else:\n",
    "        symbols = get_all_symbols(config['data_path'], config['start_date'])\n",
    "        print(f\"总共找到 {len(symbols)} 个交易对\")\n",
    "    \n",
    "    # 准备未完成的组合列表\n",
    "    remaining_combinations = []\n",
    "    for symbol in symbols:\n",
    "        for tf in config['target_timeframes']:\n",
    "            if (symbol, tf) not in optimized_combinations:\n",
    "                remaining_combinations.append((symbol, tf))\n",
    "    \n",
    "    print(f\"剩余需要优化的组合数量: {len(remaining_combinations)} 个\")\n",
    "    \n",
    "    # 使用多线程并行处理\n",
    "    import threading\n",
    "    from queue import Queue\n",
    "    \n",
    "    # 创建任务队列\n",
    "    task_queue = Queue()\n",
    "    for combo in remaining_combinations:\n",
    "        task_queue.put(combo)\n",
    "    \n",
    "    # 创建结果队列\n",
    "    result_queue = Queue()\n",
    "    \n",
    "    # 线程处理函数\n",
    "    def worker():\n",
    "        while not task_queue.empty():\n",
    "            try:\n",
    "                symbol, tf = task_queue.get(block=False)\n",
    "                print(f\"开始处理组合: {symbol}-{tf}\")\n",
    "                results = process_symbol_tf(symbol, tf, config)\n",
    "                if results:\n",
    "                    clear_output(wait=True)  # 清除当前 cell 的所有输出\n",
    "                    save_master_results(results, master_file)\n",
    "                    # 更新已优化组合，避免重复处理\n",
    "                    optimized_combinations.add((symbol, tf))\n",
    "                task_queue.task_done()\n",
    "            except Exception as e:\n",
    "                print(f\"处理任务出错: {e}\")\n",
    "                try:\n",
    "                    task_queue.task_done()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # 创建并启动多个线程\n",
    "    n_threads = min(10, len(remaining_combinations))  # 使用30个线程\n",
    "    print(f\"启动 {n_threads} 个并行线程处理任务\")\n",
    "    \n",
    "    threads = []\n",
    "    for _ in range(n_threads):\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.daemon = True\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    # 定期保存结果\n",
    "    import time\n",
    "    processed_count = 0\n",
    "    total_remaining = len(remaining_combinations)\n",
    "    \n",
    "    while any(t.is_alive() for t in threads) or not result_queue.empty():\n",
    "        # 收集并保存累积的结果\n",
    "        batch_results = []\n",
    "        while not result_queue.empty():\n",
    "            try:\n",
    "                results = result_queue.get(block=False)\n",
    "                batch_results.extend(results)\n",
    "                result_queue.task_done()\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # 如果有结果，保存它们\n",
    "        if batch_results:\n",
    "            save_master_results(batch_results, master_file)\n",
    "            # 更新计数和已优化集合\n",
    "            for res in batch_results:\n",
    "                if 'Symbol' in res and 'Target Timeframe' in res:\n",
    "                    optimized_combinations.add((res['Symbol'], res['Target Timeframe']))\n",
    "            processed_count += len(batch_results) // 5  # 每个组合有5个结果\n",
    "            print(f\"保存了 {len(batch_results)} 条结果记录，总进度: {processed_count}/{total_remaining} ({processed_count/total_remaining*100:.1f}%)\")\n",
    "        \n",
    "        # 等待一小段时间\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # 最后一次收集结果\n",
    "    batch_results = []\n",
    "    while not result_queue.empty():\n",
    "        results = result_queue.get()\n",
    "        batch_results.extend(results)\n",
    "        result_queue.task_done()\n",
    "    \n",
    "    if batch_results:\n",
    "        save_master_results(batch_results, master_file)\n",
    "        processed_count += len(batch_results) // 5\n",
    "    \n",
    "    print(f\"批量优化完成。共处理 {processed_count}/{total_remaining} 个组合。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增清理函数：清理不在最终结果 CSV 中的 optuna 数据库文件\n",
    "def clean_incomplete_optuna_db_files(config):\n",
    "    \"\"\"\n",
    "    清理不在最终优化结果 CSV 中的 optuna 数据库文件。\n",
    "    该函数会读取最终结果 CSV（如果存在），提取已完成优化的 (Symbol, Target Timeframe) 组合，\n",
    "    然后删除 reports 目录下不在该列表中的 optuna 数据库文件。\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from glob import glob\n",
    "\n",
    "    # 从最终结果 CSV 中加载已完成优化组合\n",
    "    master_file, master_df, optimized_combinations = load_master_results(config)\n",
    "    print(f\"已完成优化组合: {optimized_combinations}\")\n",
    "    \n",
    "    # 匹配与当前策略相关的 optuna 数据库文件\n",
    "    pattern = os.path.join(config['reports_path'], f\"optuna_{config['strategy']['name']}_*.db\")\n",
    "    db_files = glob(pattern)\n",
    "    for db_file in db_files:\n",
    "        filename = os.path.basename(db_file)\n",
    "        prefix = f\"optuna_{config['strategy']['name']}_\"\n",
    "        # 确保文件名格式正确\n",
    "        if filename.startswith(prefix) and filename.endswith(\".db\"):\n",
    "            # 去掉前缀和后缀，得到 \"symbol_timeframe\"\n",
    "            core = filename[len(prefix):-3]  # 去掉后面的 \".db\"\n",
    "            parts = core.rsplit(\"_\", 1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            symbol, timeframe = parts\n",
    "            # 如果此组合不在最终结果中，则删除该数据库文件\n",
    "            if (symbol, timeframe) not in optimized_combinations:\n",
    "                try:\n",
    "                    os.remove(db_file)\n",
    "                    print(f\"已删除未完成优化的数据库文件：{db_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"删除文件 {db_file} 出错：{e}\")\n",
    "    print(\"数据库清理完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化结果文件为空\n",
      "总共找到 0 个交易对\n",
      "剩余需要优化的组合数量: 0 个\n",
      "启动 0 个并行线程处理任务\n",
      "批量优化完成。共处理 0/0 个组合。\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 先清理不完整的 Optuna 数据库文件（不在最终结果 CSV 中的组合）\n",
    "    # clean_incomplete_optuna_db_files(CONFIG)\n",
    "    batch_optimize(CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backtrader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
